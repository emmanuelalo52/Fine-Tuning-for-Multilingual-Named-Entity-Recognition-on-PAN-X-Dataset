{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dataset is imported from hugging face hub\n",
    "#it consists of multiple domain. Hence, we use the get_dataset_config_names() to find the subsets available\n",
    "from datasets import get_dataset_config_names\n",
    "xtreme_subset = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"xtreme has {len(xtreme_subset)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_dataset = [s for s in xtreme_subset if s.startswith(\"PAN\")]\n",
    "panx_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "load_dataset(\"xtreme\",name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "langs = [\"de\",\"fr\",\"it\",\"en\"]\n",
    "fracs = [0.629,0.229,0.084,0.059]\n",
    "#return a datasetdict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretokenization\n",
    "for lang,frac in zip(langs,fracs):\n",
    "    #load the monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\",name=f\"PAN-X.{lang}\")\n",
    "    #shuffe and downsample each split according to how they are spoken\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split].shuffle(seed=0).select(range(int(frac*ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({lang:[panx_ch[lang][\"train\"].num_rows]for lang in langs},index=[\"Number of training samples\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key,value in element.items():\n",
    "    print(f\"{key}:{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the NER tags\n",
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a int to str to create a new column for ner \n",
    "def create_tag_names(batch):\n",
    "    return{\"ner_tags_str\":[tags.int2str(idx)for idx in batch[\"ner_tags\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"],de_example[\"ner_tags_str\"]],['Tokens','Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the frequency of each entity across a split\n",
    "from collections import Counter\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split,dataset in panx_de.items(): #check out the entire entity\n",
    "    for row in dataset[\"ner_tags_str\"]: #find the row of the dataset\n",
    "        for tag in row: #then the tag\n",
    "            if tag.startswith(\"B\"): #then value of the key\n",
    "                tag_type = tag.split(\"-\")[-1]\n",
    "                split2freqs[split][tag_type]+=1\n",
    "pd.DataFrame.from_dict(split2freqs,orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer model\n",
    "from transformers import AutoTokenizer\n",
    "bert_model = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"it is hell in here\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_token = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post processing\n",
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentencePiece Tokenizer\n",
    "sent_xlmr_token = \"\".join(xlmr_token).replace(u\"\\u2581\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_xlmr_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model classification\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    def __init__(self,config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide additional meta data that can be used to label the NER\n",
    "index2tag = {idx:tag for idx,tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx,tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model and certain constraints are downloaded\n",
    "from transformers import AutoConfig\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,num_labels=tags.num_classes,id2label=index2tag,label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available () else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name,config=xlmr_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text,return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_token,input_ids[0].numpy()],index=[\"Tokens\",\"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs,dim=-1)\n",
    "print(f\"Number of tokens in sequence:{len(xlmr_token)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    " # Get tokens with special characters\n",
    " tokens = tokenizer(text).tokens()\n",
    " # Encode the sequence into IDs\n",
    " input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    " # Get predictions as distribution over 7 possible classes\n",
    " outputs = model(input_ids)[0]\n",
    " # Take argmax to get most likely class per token\n",
    " predictions = torch.argmax(outputs, dim=2)\n",
    " # Convert to DataFrame\n",
    " preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    " return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect words and tags as lists\n",
    "words,labels = de_example[\"tokens\"],de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenized_input = xlmr_tokenizer(de_example[\"tokens\"],is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(Tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens],index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_id = Tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens,words_id],index=[\"Tokens\",\"Words IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify special tokens as [-100]\n",
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "for word_idx in words_id:\n",
    "    if word_idx is None  or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in labels]\n",
    "index = [\"Token\",\"Word IDs\",\"Label IDs\",\"Labels\"]\n",
    "pd.DataFrame([tokens,words_id,label_ids,labels],index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we do same for a whole dataset\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"],truncation=True,is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx,label    in enumerate(examples[\"ner_tags\"]):\n",
    "        words_id = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in words_id:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate all the encoded inputs\n",
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels,batched=True,remove_columns=['langs','ner_tags','tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],[\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],[\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert the list to a seqeval list\n",
    "import numpy as np\n",
    "def align_predictions(predictions,label_ids):\n",
    "    preds = np.argmax(predictions,axis=2)\n",
    "    batch_size,seq_len = preds.shape\n",
    "    labels_list,preds_list = [],[]\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels,example_preds = [],[]\n",
    "        #hide the special token during training\n",
    "        for seq_idx in range(seq_len):\n",
    "            if label_ids[batch_idx,seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "    return preds_list,labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning the XLM-Roberta transformer \n",
    "from transformers import TrainingArguments\n",
    "num_epochs = 3\n",
    "batch_size = 30\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    " output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
    " per_device_train_batch_size=batch_size,\n",
    " per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
    " save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    " logging_steps=logging_steps, push_to_hub=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "def compute_metrics(eval_pred):\n",
    " y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    " eval_pred.label_ids)\n",
    " return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    " return (XLMRobertaForTokenClassification\n",
    " .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    " .to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass all the information in an encoded dataset\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    " data_collator=data_collator, compute_metrics=compute_metrics,\n",
    " train_dataset=panx_de_encoded[\"train\"],\n",
    " eval_dataset=panx_de_encoded[\"validation\"],\n",
    " tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a loop \n",
    "trainer.train() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"training successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de,tags,trainer.model,xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "        # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7),\n",
    "    labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the function in a full dataset\n",
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(lambda x: x['loss'][:len(x[\"input_ids\"])],axis=1)\n",
    "df['predicted_label'] = df.apply(lambda x: x['predicted_label'][:len(x['input_ids'])],axis=1)\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack the tokens of a single line into a lsit\n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens['loss'] = df_tokens['loss'].astype(float).round(2)\n",
    "df_tokens.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\",\"mean\",\"sum\"])\n",
    "    .droplevel(level=0,axis=1)#get rid of multi columns\n",
    "    .sort_values(by=\"sum\",ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\",\"mean\",\"sum\"])\n",
    "    .droplevel(level=0,axis=1)#get rid of multi columns\n",
    "    .sort_values(by=\"mean\",ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "def plot_confusion_matrix(y_preds,y_true,labels):\n",
    "    cm = confusion_matrix(y_true,y_preds,normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\",values_format=\".2f\",ax=ax,colorbar=False)\n",
    "    plt.title(\"Normalised confusion matrix\")\n",
    "    plt.show\n",
    "plot_confusion_matrix(df_tokens[\"labels\"],df_tokens[\"predicted_label\"],tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _,row in df.iterrow():\n",
    "        labels,preds,tokens,losses = [],[],[],[]\n",
    "        for i in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0,len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\":tokens,\"labels\":labels,\"preds\":preds,\"losses\":losses}).T\n",
    "        yield df_tmp\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\",ascending=False).head(3)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error analysis across multiple languages\n",
    "def get_f1_score(trainer,dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer,panx_de_encoded[\"test\"])\n",
    "print(f\"F1_score of [de] model on [de] dataset:{f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr,tags,trainer.model,xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translating the entire deutsche dataset to french\n",
    "def evaluate_lang_performance(lang,trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[\"lang\"])\n",
    "    return get_f1_score(trainer,panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\",trainer)\n",
    "print(f\"F1_score for [de] model on [fr] is {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct our model for zero shot transfer\n",
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict({\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we test the performance on 250 corpus\n",
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do this on 500-4000 corpus\n",
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.axhline(f1_scores[\"de\"][\"fr\"],ls=\"--\",color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning on multiple languages at once (multilingual)\n",
    "from datasets import concatenate_datasets\n",
    "def concatenate_splits(corpora):\n",
    "    multicorpus = DatasetDict()\n",
    "    for split in corpora[0].keys:\n",
    "        multicorpus[split] = concatenate_datasets([corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    return multicorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model_init=model_init, args=training_args,data_collator=data_collator, compute_metrics=compute_metrics,tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],eval_dataset=panx_de_fr_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune on the remaining languages with our train_on_subset() function\n",
    "corpora = [panx_de_encoded]\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    #Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model_init=model_init, args=training_args,data_collator=data_collator, compute_metrics=compute_metrics,tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],eval_dataset=corpora_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, lang in enumerate(langs):\n",
    "    f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])\n",
    "\n",
    "scores_data = {\"de\": f1_scores[\"de\"],\"each\": {lang: f1_scores[lang][lang] for lang in langs},\"all\": f1_scores[\"all\"]}\n",
    "\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",inplace=True)\n",
    "f1_scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
